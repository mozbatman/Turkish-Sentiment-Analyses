{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish Sentiment Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN (yenilenen sinir aÄŸÄ±) modelleri arasÄ±nda GRU modeli kullanÄ±ldÄ±."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr    # SESÄ° METÄ°NE Ã‡EVÄ°RMEK Ä°Ã‡Ä°N\n",
    "import numpy as np \n",
    "import pandas as pd                # DATA SETÄ°NÄ° OKUMA VE DÃœZENLEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN MODELÄ°NÄ° KURMAK Ä°Ã‡Ä°N KERAS KUTUPHANESÄ°NÄ° KULLANACAÄžIZ\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data set okuma\n",
    "dataset = pd.read_csv('hepsiburada.csv') \n",
    "\n",
    "etiket = dataset['Rating'].values.tolist()  # pandas serisi olarak alÄ±nÄ±yor o yÃ¼zden to list yaptÄ±k\n",
    "data = dataset['Review'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test setini ayÄ±rma %80 train %20 test ÅŸeklinde\n",
    "bol_say = int(len(data) * 0.80) # %80 kÄ±sÄ±m hangi sayÄ±ya kadar ogrenÄ±yoruz\n",
    "x_train, x_text = data[:bol_say], data[bol_say:] \n",
    "y_train, y_test = etiket[:bol_say], etiket[bol_say:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data setteki en cok kullanÄ±lan 10000 kelimeyi  ayÄ±rarak gerisini yok sayÄ±yoruz\n",
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TokenleÅŸtirme\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train) ## egitim setini tokenleÅŸtirdik\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN aynÄ± boyutta veri kÃ¼melerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan datalar kÄ±saltcaz veya 0 atarak uzatcaz (eÅŸitlemek iÃ§in)\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens ]   ## her yorumda kac token oldugu hesaplanÄ±r\n",
    "num_tokens = np.array(num_tokens) ## dizi numpy arraye ceviriyoruz\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens) ## cumlelerin ortalama kelime sayÄ±sÄ±nÄ±n 2 fazlasÄ±yla standart sapmasÄ±nÄ± topluyoruz\n",
    "max_tokens = int(max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pading ekleme \n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens) # pad_sequences keras kutupanesÄ±nÄ±n fonksÄ±yonudur\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MODELÄ°N OLUSTURULMASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() ## ardÄ±ÅŸÄ±k model oluÅŸturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50 ## kullanÄ±lcak kelime vektÃ¶rlerinin uzunluÄŸu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programlar\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# input iÃ§indeki kelimelerin vektÃ¶rlerini output olarak verir\n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer'))          ## 10000 e 50 boyutunda matris oluÅŸturuyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programlar\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model.add(GRU(units= 16, return_sequences=True)) # unit = 16 00 nÃ¶ron sayÄ±sÄ± // return_sequence bir sonraki layerlarÄ± ekleyecegÄ±mÄ±z Ä±cÄ±n true\n",
    "model.add(GRU(units= 8, return_sequences=True))\n",
    "model.add(GRU(units= 4)) # son noron oldugu Ä±cÄ±n return_sequeces oto false bÄ±rakÄ±yoruz\n",
    "model.add(Dense(1, activation='sigmoid')) # cÄ±kÄ±s noronu oldugu Ä±cÄ±n Dense kullanÄ±ldÄ± ve sigmoid fonk 0 ile 1 arasÄ± degerler doner yanÄ± mutlu ve mutsuz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizasyon\n",
    "optimizer = Adam(lr= 1e-3)  # 1e-3 ==== 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programlar\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Modelin Derlenmesi \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy']) # yanlÄ±zca 2 sÄ±nÄ±f oldugu Ä±cÄ±n loss iÃ§in binary_crossentropy kullandÄ±k // metris masarÄ± oranÄ±nÄ± gormek Ä±cÄ±n kullanÄ±ldÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "194797/194797 [==============================] - 50s 258us/sample - loss: 0.1694 - acc: 0.9556\n",
      "Epoch 2/5\n",
      "194797/194797 [==============================] - 50s 254us/sample - loss: 0.0884 - acc: 0.9723\n",
      "Epoch 3/5\n",
      "194797/194797 [==============================] - 51s 260us/sample - loss: 0.0683 - acc: 0.9793\n",
      "Epoch 4/5\n",
      "194797/194797 [==============================] - 51s 263us/sample - loss: 0.0537 - acc: 0.9847\n",
      "Epoch 5/5\n",
      "194797/194797 [==============================] - 51s 263us/sample - loss: 0.0424 - acc: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2654af46848>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MODELÄ°N EÄžÄ°TÄ°MÄ°\n",
    "model.fit(x_train_pad, y_train, epochs=5, batch_size=256) # epochs == verilerin kac kez eÄŸitileceÄŸi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak : \n",
      "soylediginiz : iÄŸrenÃ§ bir mekan\n",
      "[[0.0691001]]\n",
      "Negatif : ðŸ™\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "import emoji\n",
    "facesmiling='\\U0001F600'\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print('speak : ')\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "    try:\n",
    "        text = r.recognize_google(audio, language='tr-tr')\n",
    "        print(\"soylediginiz : {}\".format(text))\n",
    "        texts = [text]\n",
    "        tokens = tokenizer.texts_to_sequences(texts)\n",
    "        tokens_pad = pad_sequences(tokens, maxlen= max_tokens)\n",
    "        deger = model.predict(tokens_pad)\n",
    "        print(deger)\n",
    "        if deger > 0.5:\n",
    "            print('Pozitif : \\U0001F642')\n",
    "        else:\n",
    "            print('Negatif : \\U0001F641') \n",
    "        \n",
    "    except:\n",
    "        print(\"anlamadÄ±m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkish Sentiment Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN (yenilenen sinir ağı) modelleri arasında GRU modeli kullanıldı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr    # SESİ METİNE ÇEVİRMEK İÇİN\n",
    "import numpy as np \n",
    "import pandas as pd                # DATA SETİNİ OKUMA VE DÜZENLEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN MODELİNİ KURMAK İÇİN KERAS KUTUPHANESİNİ KULLANACAĞIZ\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data set okuma\n",
    "dataset = pd.read_csv('hepsiburada.csv') \n",
    "\n",
    "etiket = dataset['Rating'].values.tolist()  # pandas serisi olarak alınıyor o yüzden to list yaptık\n",
    "data = dataset['Review'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test setini ayırma %80 train %20 test şeklinde\n",
    "bol_say = int(len(data) * 0.80) # %80 kısım hangi sayıya kadar ogrenıyoruz\n",
    "x_train, x_text = data[:bol_say], data[bol_say:] \n",
    "y_train, y_test = etiket[:bol_say], etiket[bol_say:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data setteki en cok kullanılan 10000 kelimeyi  ayırarak gerisini yok sayıyoruz\n",
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenleştirme\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train) ## egitim setini tokenleştirdik\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RNN aynı boyutta veri kümelerinde çalıştığından datalar kısaltcaz veya 0 atarak uzatcaz (eşitlemek için)\n",
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens ]   ## her yorumda kac token oldugu hesaplanır\n",
    "num_tokens = np.array(num_tokens) ## dizi numpy arraye ceviriyoruz\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens) ## cumlelerin ortalama kelime sayısının 2 fazlasıyla standart sapmasını topluyoruz\n",
    "max_tokens = int(max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pading ekleme \n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens) # pad_sequences keras kutupanesının fonksıyonudur\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MODELİN OLUSTURULMASI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() ## ardışık model oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50 ## kullanılcak kelime vektörlerinin uzunluğu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programlar\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# input içindeki kelimelerin vektörlerini output olarak verir\n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer'))          ## 10000 e 50 boyutunda matris oluşturuyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programlar\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model.add(GRU(units= 16, return_sequences=True)) # unit = 16 00 nöron sayısı // return_sequence bir sonraki layerları ekleyecegımız ıcın true\n",
    "model.add(GRU(units= 8, return_sequences=True))\n",
    "model.add(GRU(units= 4)) # son noron oldugu ıcın return_sequeces oto false bırakıyoruz\n",
    "model.add(Dense(1, activation='sigmoid')) # cıkıs noronu oldugu ıcın Dense kullanıldı ve sigmoid fonk 0 ile 1 arası degerler doner yanı mutlu ve mutsuz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizasyon\n",
    "optimizer = Adam(lr= 1e-3)  # 1e-3 ==== 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programlar\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Modelin Derlenmesi \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy']) # yanlızca 2 sınıf oldugu ıcın loss için binary_crossentropy kullandık // metris masarı oranını gormek ıcın kullanıldı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "194797/194797 [==============================] - 50s 258us/sample - loss: 0.1694 - acc: 0.9556\n",
      "Epoch 2/5\n",
      "194797/194797 [==============================] - 50s 254us/sample - loss: 0.0884 - acc: 0.9723\n",
      "Epoch 3/5\n",
      "194797/194797 [==============================] - 51s 260us/sample - loss: 0.0683 - acc: 0.9793\n",
      "Epoch 4/5\n",
      "194797/194797 [==============================] - 51s 263us/sample - loss: 0.0537 - acc: 0.9847\n",
      "Epoch 5/5\n",
      "194797/194797 [==============================] - 51s 263us/sample - loss: 0.0424 - acc: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2654af46848>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MODELİN EĞİTİMİ\n",
    "model.fit(x_train_pad, y_train, epochs=5, batch_size=256) # epochs == verilerin kac kez eğitileceği"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak : \n",
      "soylediginiz : iğrenç bir mekan\n",
      "[[0.0691001]]\n",
      "Negatif : 🙁\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "import emoji\n",
    "facesmiling='\\U0001F600'\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print('speak : ')\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "    try:\n",
    "        text = r.recognize_google(audio, language='tr-tr')\n",
    "        print(\"soylediginiz : {}\".format(text))\n",
    "        texts = [text]\n",
    "        tokens = tokenizer.texts_to_sequences(texts)\n",
    "        tokens_pad = pad_sequences(tokens, maxlen= max_tokens)\n",
    "        deger = model.predict(tokens_pad)\n",
    "        print(deger)\n",
    "        if deger > 0.5:\n",
    "            print('Pozitif : \\U0001F642')\n",
    "        else:\n",
    "            print('Negatif : \\U0001F641') \n",
    "        \n",
    "    except:\n",
    "        print(\"anlamadım\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
